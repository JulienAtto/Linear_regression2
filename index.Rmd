---
title: "Multiple Linear Regression"
author: "Essé Julien Atto"
output:
  html_document:
    code_folding: hide
    keep_md: true
    toc: true 
    toc_depth: 2 
    toc_float: true 
    number_sections: true  
    theme: united
    highlight: espresso
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,message = FALSE,warning = FALSE)
```

```{r,echo=FALSE}
rm(list=ls())  #cleaning my  environment

```


```{r load_libraries,message=FALSE,warning=F}
#loading libraries to use
library(dplyr)
library(datasets) #for mtcars data
library(ggplot2)
library(scatterplot3d)
library(stringr)
library(magick)
```

Multiple linear regression is a statistical method for finding a linear relationship between $n$ explanatory variables $X_1, X_2, \cdots, X_n$ $(n\geq 2)$ and a variable to be explained $y$:
\[y= \theta_0 + \theta_1 X_1 + \theta_2 X_2 + \cdots + \theta_n X_n.\]

# Data preparation and visualisation
```{r load_data}
#Loading mtcars data
data(mtcars)
```

The data **mtcars** in R package **datasets** was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973–74 models). We will use the following variables:

* mpg: Miles(US) gallon

* disp: Displacement (cu.in.)

* wt: Weight(100o lbs).


## Visualization of 10 rows chosen randomly among the 32 observations
```{r view_data}
set.seed(1234)
mtcars%>%
  mutate(carnames=rownames(mtcars))%>%
  filter(carnames%in%sample(carnames,10))%>%
  select(mpg,disp,wt)
  
```


## Graph
```{r graph}
x =mtcars$disp 
y =mtcars$wt
z =mtcars$mpg

scatterplot3d::scatterplot3d(x, y,z, pch = 19, type = "h", color = "red",
                     main = "Miles/(US) gallon as a function of engine Displacement and car Weight",xlab = "Displacement (cu.in.)",ylab = "Weight (x1000 lbs)",zlab = "Miles/(US) gallon",
                     grid = T, box = F,  
                     mar = c(2.5, 2.5, 2, 1.5), angle = 60)
```

# Linear regresson using Gradient Descent
## Computation of the parameters

```{r GD_and_plots}
#X and y
X<-with(mtcars,cbind(disp,wt))

y=with(mtcars,cbind(mpg))

# initializing fitting parameters
theta = cbind(numeric(3)) 

#loading  some functions... 
source("myfunctions.R")

##############################################################
  # Running Gradient Descent and plotting cost as function of number of iterations for some values of the learning rate.

  ALPHA<-c(0.3,0.1,0.03,0.01)
  COL<-c("red","blue","green","yellow")
  nb_iter<-NULL #initialiation of vector containing number of iterations for each value of alpha
  out<-list()
  Cost_by_iter<-list()
  
  for(i in 1:length(ALPHA)){
    # Initializing  theta and running Gradient Descent 
    theta = matrix(0,3)
    Grad_Desc<- Grad_Desc_fct(X, y, theta, alpha = ALPHA[i], max_iter=10000)
    theta<-Grad_Desc$theta
    Cost_by_iter[[i]]<-Grad_Desc$Cost_by_iter
    nb_iter=append(nb_iter,Grad_Desc$nb_iter)
    out[[i]]<-theta 
    } # end of for(i in 1:length(ALPHA))
  
    # Plot the convergence graph for different values of alpha
    
      plot(1:nrow(Cost_by_iter[[1]]), Cost_by_iter[[1]], type="l",lwd=2,xlab='Number of iterations',ylab='Cost',col=COL[1],
           main=expression(paste("Convergence of gradient descent for a given learning rate ",alpha)),xlim = c(0,min(max(nb_iter),400)))
      
    for(i in 2:length(ALPHA)){
      lines(1:nrow(Cost_by_iter[[i]]), Cost_by_iter[[i]], type="l",lwd=2,col=COL[i])
      }
    

  legend("topright", 
         legend =sapply(ALPHA, function(.) as.expression(bquote(alpha==.(.)))), 
         lwd = 2, cex = 1.2, col = COL, lty = rep(1,4))
```

```{r,echo=FALSE}
names(out)<-paste(ALPHA)

```

If we choose $\alpha=0.01$, then we have:
```{r,echo=FALSE}
theta<-out$`0.01`
```

\[\theta=\begin{pmatrix} `r theta[1]`\\`r theta[2]` \\`r theta[3]` \end{pmatrix}\]

## Plotting the regression plane
```{r static_plot}
#static plot
static_plot(60)
```



```{r animated_plot}
##animated plot
anime_plot()

```

```{r Reg3Dplots}
knitr::include_graphics("myReg3Dplots.gif")
```

## Predictions
* **Predict number of Miles/(US) gallon (mpg) for a Displacement of 300.0 cu.in. and a Weight of 4500 lbs** ($4.500\times 1000 lbs$):
```{r pred1}
mpg_for_300_4.5 = c(c(1, 300,4.5)%*%theta)
```

$\qquad\quad$For a Displacement = 300 cu.in  and a Weight=4500 lbs, we predict **`r round( mpg_for_300_4.5,2)`** miles/(US) gallon (mpg).

\
&nbsp;

* **Predict number of Miles/(US) gallon (mpg) for a Displacement of 130.0 cu.in. and a Weight of 2650 lbs** ($2.650\times 1000 lbs$):
```{r pred2}
mpg_for_130_2.65 = c(c(1, 130,2.65)%*%theta)
```

$\qquad\quad$For a Displacement = 130 cu.in  and a Weight=2650 lbs, we predict **`r round( mpg_for_130_2.65,2)`** miles/(US) gallon (mpg).

# Multiple Linear Regression using lm() function of R (Normal equation)

\[\theta=(X^TX)^{-1}X^Ty.\]

```{r lm_mod}
model_lm<-lm(mpg~disp + wt,data =mtcars)

model_lm
```

We can see that the values of the fitted parameters are $\hat{\theta_0}=`r round(model_lm[['coefficients']][1],5)`, \quad\hat{\theta_1}=`r round(model_lm[['coefficients']][2],5)`$, and  $\hat{\theta_2}=`r round(model_lm[['coefficients']][3],5)`$.

## Summary of the model
```{r lm_summary}
summary(model_lm)
```




## Predictions
* **Predict number of Miles/(US) gallon (mpg) for a Displacement of 300.0 cu.in. and a Weight of 4500 lbs** ($4.500\times 1000 lbs$):
```{r pred1bis}
mpg_for_300_4.5_ =predict.lm(model_lm,data.frame(disp=300,wt=4.5))
```

$\qquad\quad$For a Displacement = 300 cu.in  and a Weight=4500 lbs, we predict **`r round( mpg_for_300_4.5_,2)`** miles/(US) gallon (mpg).

\
&nbsp;

* **Predict number of Miles/(US) gallon (mpg) for a Displacement of 130.0 cu.in. and a Weight of 2650 lbs** ($2.650\times 1000 lbs$):
```{r pred2bis}
mpg_for_130_2.65_ = predict.lm(model_lm,data.frame(disp=130,wt=2.65))
```

$\qquad\quad$For a Displacement = 130 cu.in  and a Weight=2650 lbs, we predict **`r round( mpg_for_130_2.65_,2)`** miles/(US) gallon (mpg).
